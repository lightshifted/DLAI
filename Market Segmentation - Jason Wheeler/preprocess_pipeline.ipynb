{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YMmLw_1JWwCR"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31651,
     "status": "ok",
     "timestamp": 1611520710597,
     "user": {
      "displayName": "Jason Wheeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9q6Y0NfCF9E2BEUL44aGRfQeUmeqdSzhKgtJp6Ok=s64",
      "userId": "11471174883115528364"
     },
     "user_tz": 360
    },
    "id": "czK9xXaDWwCW",
    "outputId": "162ad4d6-b3c9-491c-d772-18311f74b66c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hedronstone\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "pageview_hist = pd.read_csv('data/pageview_hist.csv', encoding='utf-8').fillna(0)\n",
    "hubspot_export = pd.read_csv('data/hubspot_export.csv', encoding='utf-8').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31022,
     "status": "ok",
     "timestamp": 1611520710766,
     "user": {
      "displayName": "Jason Wheeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9q6Y0NfCF9E2BEUL44aGRfQeUmeqdSzhKgtJp6Ok=s64",
      "userId": "11471174883115528364"
     },
     "user_tz": 360
    },
    "id": "bgOPRcuASiaB",
    "outputId": "25e715ce-8e15-4b9a-8115-6b1881c95e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageviews shape: (90533, 9)\n"
     ]
    }
   ],
   "source": [
    "# locate null exclusive rows and remove them\n",
    "pageviews = pageview_hist.drop(list(np.ravel(np.where(\\\n",
    "                                    pageview_hist['Last Page Seen Current Value'] == 0))))\n",
    "\n",
    "# print updated array\n",
    "print('pageviews shape:', pageviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XWJITnO0XCU"
   },
   "source": [
    "### Url Encoding\n",
    "The following cells contain gnarly code. You've been warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B6es1CIfS4_z"
   },
   "outputs": [],
   "source": [
    "def encode_urls(x, s, m):\n",
    "  \"\"\"\n",
    "  Encodes urls based on prespecified criteria.\n",
    "  Inputs:\n",
    "  x: vector of urls\n",
    "  s: vector name\n",
    "  m: array of urls\n",
    "  Returns:\n",
    "  x: array of encoded urls\n",
    "  \"\"\"  \n",
    "  # find indices of the rows containing specified strings \n",
    "  blog = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('blog') == True)]\n",
    "  batch = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('thebatch') == True)]\n",
    "  specialization = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('specialization') == True)]\n",
    "  yearning = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('yearning') == True)]\n",
    "  signup = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('course-signup') == True)]\n",
    "  ambassador = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('ambassador') == True)]\n",
    "  forum = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('forum') == True)]\n",
    "  terms = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('terms') == True)]\n",
    "  events = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('events') == True)]\n",
    "  unsub = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('unsubscribe') == True)]\n",
    "  course = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('utm_campaign') == True)]\n",
    "  career = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('career') == True)]\n",
    "  post = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('post_type') == True)]\n",
    "  med = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('ai-for-medicine') == True)]\n",
    "  climate = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('climate') == True)]\n",
    "  about = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('about') == True)]\n",
    "  ainots = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('ai-nots') == True)]\n",
    "  tensor = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('tensor') == True)]\n",
    "  aicourse = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('ai-for-everyone') == True)]\n",
    "  subscribe = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('subscribe') == True)]\n",
    "  register = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('share') == True)]\n",
    "  medicine = x[f'{s}'].iloc[np.where(x[f'{s}'].str.contains('https://www.deeplearning.ai/ai-for-medicine/') == True)]\n",
    "  home = x[f'{s}'].iloc[np.where(x[f'{s}'] == 'https://www.deeplearning.ai/')]\n",
    "  contact = x[f'{s}'].iloc[np.where(x[f'{s}'] == 'https://www.deeplearning.ai/contact-us/')]\n",
    "  press = x[f'{s}'].iloc[np.where(x[f'{s}'] == 'https://www.deeplearning.ai/press/')]\n",
    "\n",
    "  # map string to corresponding index\n",
    "  blog = blog.map({i:'blog' for i in blog})\n",
    "  batch = batch.map({i:'batch' for i in batch})\n",
    "  specialization = specialization.map({i:'specialization' for i in specialization})\n",
    "  yearning = yearning.map({i:'yearning' for i in yearning})\n",
    "  signup = signup.map({i:'course signup' for i in signup})\n",
    "  ambassador = ambassador.map({i:'ambassador' for i in ambassador})\n",
    "  forum = forum.map({i:'forum' for i in forum})\n",
    "  terms = terms.map({i:'terms' for i in terms})\n",
    "  events = events.map({i:'events' for i in events})\n",
    "  unsub = unsub.map({i:'unsubscribe' for i in unsub})\n",
    "  course = course.map({i:'course' for i in course})\n",
    "  career = career.map({i:'career' for i in career})\n",
    "  post = post.map({i:'blog' for i in post})\n",
    "  med = med.map({i:'course' for i in med})\n",
    "  climate = climate.map({i:'climate' for i in climate})\n",
    "  about = about.map({i:'about' for i in about})\n",
    "  ainots = ainots.map({i:'course' for i in ainots})\n",
    "  tensor = tensor.map({i:'course' for i in tensor})\n",
    "  aicourse = aicourse.map({i:'course' for i in aicourse})\n",
    "  subscribe = subscribe.map({i:'subscribe' for i in subscribe})\n",
    "  register = register.map({i:'register' for i in register})\n",
    "  medicine = medicine.map({i:'course' for i in medicine})\n",
    "  home = home.map({i:'home' for i in home})\n",
    "  contact = contact.map({i:'contact' for i in contact})\n",
    "  press = press.map({i:'press' for i in press})\n",
    "\n",
    "  # replace original strings with newly encoded strings\n",
    "  m[f'{s}'].iloc[blog.index] = blog\n",
    "  m[f'{s}'].iloc[batch.index] = batch\n",
    "  m[f'{s}'].iloc[specialization.index] = specialization\n",
    "  m[f'{s}'].iloc[yearning.index] = yearning\n",
    "  m[f'{s}'].iloc[signup.index] = signup\n",
    "  m[f'{s}'].iloc[ambassador.index] = ambassador\n",
    "  m[f'{s}'].iloc[forum.index] = forum\n",
    "  m[f'{s}'].iloc[terms.index] = terms\n",
    "  m[f'{s}'].iloc[events.index] = events\n",
    "  m[f'{s}'].iloc[unsub.index] = unsub\n",
    "  m[f'{s}'].iloc[med.index] = med\n",
    "  m[f'{s}'].iloc[course.index] = course\n",
    "  m[f'{s}'].iloc[career.index] = career\n",
    "  m[f'{s}'].iloc[post.index] = post\n",
    "  m[f'{s}'].iloc[climate.index] = climate\n",
    "  m[f'{s}'].iloc[about.index] = about\n",
    "  m[f'{s}'].iloc[ainots.index] = ainots\n",
    "  m[f'{s}'].iloc[tensor.index] = tensor\n",
    "  m[f'{s}'].iloc[aicourse.index] = aicourse\n",
    "  m[f'{s}'].iloc[subscribe.index] = subscribe\n",
    "  m[f'{s}'].iloc[register.index] = register\n",
    "  m[f'{s}'].iloc[medicine.index] = medicine\n",
    "  m[f'{s}'].iloc[home.index] = home\n",
    "  m[f'{s}'].iloc[contact.index] = contact\n",
    "  m[f'{s}'].iloc[press.index] = press\n",
    "\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7537,
     "status": "ok",
     "timestamp": 1611520957232,
     "user": {
      "displayName": "Jason Wheeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9q6Y0NfCF9E2BEUL44aGRfQeUmeqdSzhKgtJp6Ok=s64",
      "userId": "11471174883115528364"
     },
     "user_tz": 360
    },
    "id": "Q759XO-8bU9D",
    "outputId": "6a321634-01a5-4bbf-bdcf-3377fd21c5ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hedronstone\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# encode url array \n",
    "update = encode_urls(pageviews, 'Last Page Seen Current Value', pageview_hist)\n",
    "update = encode_urls(pageviews, 'Last Page Seen Previous Value (1)', update)\n",
    "update = encode_urls(pageviews, 'Last Page Seen Previous Value (2)', update)\n",
    "update = encode_urls(pageviews, '...', update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HomJ2efZgik4"
   },
   "outputs": [],
   "source": [
    "# create dictionary containing encoded string and integer pairings\n",
    "dic = { 'events': 1, 'blog': 2, 'course': 3, 'batch': 4, 'yearning': 5,\n",
    "'specialization': 6, 'home': 7, 'career': 8, 'forum': 9, 'register': 10, 'contact': 11,\n",
    "'course signup': 12, 'climate': 13, 'about': 14, 'subscribe': 15,\n",
    "'ambassador': 16, 'terms': 17, 'press': 18 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X2w6Ui1Za5R"
   },
   "outputs": [],
   "source": [
    "# take each encoded url and find then record its location in our original array\n",
    "locations = [np.where((hubspot_export['Contact ID'] == i) == True)\\\n",
    "             for i in update['Contact ID'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2393727,
     "status": "ok",
     "timestamp": 1611523364228,
     "user": {
      "displayName": "Jason Wheeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj9q6Y0NfCF9E2BEUL44aGRfQeUmeqdSzhKgtJp6Ok=s64",
      "userId": "11471174883115528364"
     },
     "user_tz": 360
    },
    "id": "etnF3FvuqpEs",
    "outputId": "52aa6fbd-f919-409c-bfd0-0f26584305c9"
   },
   "outputs": [],
   "source": [
    "df = hubspot_export.iloc[np.ravel(locations).tolist()]\n",
    "df['url0'] = 0\n",
    "df['url1'] = 0\n",
    "df['url2'] = 0\n",
    "df['url3'] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "  df['url0'].iloc[i] = update['Last Page Seen Current Value'].iloc[i]\n",
    "  df['url1'].iloc[i] = update['Last Page Seen Previous Value (1)'].iloc[i]\n",
    "  df['url2'].iloc[i] = update['Last Page Seen Previous Value (2)'].iloc[i]\n",
    "  df['url3'].iloc[i] = update['...'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLQfEZOhtsFU"
   },
   "outputs": [],
   "source": [
    "df['url0'] = df['url0'].map(dic).fillna(0).astype('int64')\n",
    "df['url1'] = df['url1'].map(dic).fillna(0).astype('int64')\n",
    "df['url2'] = df['url2'].map(dic).fillna(0).astype('int64')\n",
    "df['url3'] = df['url3'].map(dic).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD1SAGBgY9J4"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign pageviews to X\n",
    "X = pageviews\n",
    "\n",
    "# drop samples without pageview history\n",
    "pageviews = df.drop(list(np.ravel(np.where(\n",
    "    df['url0'] == 0 \n",
    "    ))))\n",
    "\n",
    "# drop useless column\n",
    "pageviews = pageviews.drop(columns='Unnamed: 0')\n",
    "\n",
    "# create dictionary of country encodings \n",
    "countries = dict(zip(X['IP Country'].unique(), list(range(len(X)))))\n",
    "\n",
    "# map encodings to X\n",
    "X['IP Country'] = X['IP Country'].map(countries)\n",
    "\n",
    "# create column identifying interested learners where\n",
    "# (purchase = 1) and (non-purchase = 0)\n",
    "r,m = np.where(X.iloc[:, 5:9] == 6)\n",
    "\n",
    "# map encoding to 'purchase'\n",
    "X['purchase'] = 0\n",
    "X['purchase'].iloc[r] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2drop = [\n",
    " 'Became a Lead Date',\n",
    " 'Became a Subscriber Date',\n",
    " 'Became an Opportunity Date',\n",
    " 'First Conversion Date',\n",
    " 'First marketing email click date',\n",
    " 'First marketing email open date',\n",
    " 'First marketing email send date',\n",
    " 'Last Activity Date',\n",
    " 'Last marketing email click date',\n",
    " 'Last marketing email name',\n",
    " 'Last marketing email open date',\n",
    " 'Last marketing email send date',\n",
    " 'First Page Seen',\n",
    " 'Last Page Seen',\n",
    " 'Marketing emails opened',\n",
    " 'Marketing emails delivered',\n",
    " 'Marketing emails clicked',\n",
    " 'Opted out of email: Events and Community',\n",
    " 'Opted out of email: Program Announcements',\n",
    " 'Opted out of email: The Batch',\n",
    " 'Unsubscribed from all email',\n",
    " 'Which of the following online courses have you taken from deeplearning.ai?',\n",
    " 'Last Registered Event',\n",
    " 'Last Registered Event Date',\n",
    " 'Number of event completions',\n",
    " 'Highest level of completed education',\n",
    " 'Job Title or Function',\n",
    " 'IP Country Code',\n",
    " 'Associated Company ID',]\n",
    "\n",
    "# drop columns and store in X\n",
    "X = pageviews.drop(columns=cols2drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of country encodings \n",
    "countries = dict(zip(X['IP Country'].unique(), list(range(len(X)))))\n",
    "\n",
    "# map encodings to X\n",
    "X['IP Country'] = X['IP Country'].map(countries)\n",
    "\n",
    "# create column identifying interested learners where\n",
    "# (purchase = 1) and (non-purchase = 0)\n",
    "r,m = np.where(X.iloc[:, 5:9] == 6)\n",
    "\n",
    "# map encoding to 'purchase'\n",
    "X['purchase'] = 0\n",
    "X['purchase'].iloc[r] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUkjUHsTFOtm/PQq+Lf8zz",
   "collapsed_sections": [],
   "name": "url_preprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
